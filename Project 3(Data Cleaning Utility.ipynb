{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b99db13a-004f-4c79-a04a-8fb45d71e045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "631be421-dffd-4e0d-8bc7-c970fe4008b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "     ID       Full Name          Age     Join Date   Salary Department\n",
      "0    1    Rahul Sharma           25    2022-01-15  35000.0         IT\n",
      "1    2     Priya Verma          NaN    2021/05/20  42000.0         HR\n",
      "2    3      Amit Singh           28    15-07-2022  39000.0    Finance\n",
      "3    4      Neha Gupta           27    2022-03-10      NaN         IT\n",
      "4    5     Rohit Kumar           30    2021-11-05  48000.0      Sales\n",
      "5    6    Anjali Mehta           29    2022-01-15  35000.0         IT\n",
      "6    6    Anjali Mehta           29    2022-01-15  35000.0         IT\n",
      "7    7    Suresh Patel          NaN    2020-08-18  41000.0         HR\n",
      "8    8      Pooja Shah           26  invalid_date  37000.0    Finance\n",
      "9    9  Karan Malhotra           31    2022-06-25  50000.0        NaN\n",
      "10  10     Simran Kaur           24    2023-02-12  32000.0  Marketing\n",
      "11  11             NaN           27    2021-09-14  36000.0         IT\n",
      "12  12     Vikas Yadav  twenty five    2022-12-01  40000.0         HR\n"
     ]
    }
   ],
   "source": [
    "# Read Dataset\n",
    "df = pd.read_csv(\"dirty_data.csv\")\n",
    "log = []\n",
    "print(\"Original Data:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2abef3eb-2e2e-45da-818a-3ca9a07e4a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "\n",
      "    ID       Full Name          Age     Join Date   Salary Department\n",
      "0    1    Rahul Sharma           25    2022-01-15  35000.0         IT\n",
      "1    2     Priya Verma          NaN    2021/05/20  42000.0         HR\n",
      "2    3      Amit Singh           28    15-07-2022  39000.0    Finance\n",
      "3    4      Neha Gupta           27    2022-03-10      NaN         IT\n",
      "4    5     Rohit Kumar           30    2021-11-05  48000.0      Sales\n",
      "5    6    Anjali Mehta           29    2022-01-15  35000.0         IT\n",
      "6    6    Anjali Mehta           29    2022-01-15  35000.0         IT\n",
      "7    7    Suresh Patel          NaN    2020-08-18  41000.0         HR\n",
      "8    8      Pooja Shah           26  invalid_date  37000.0    Finance\n",
      "9    9  Karan Malhotra           31    2022-06-25  50000.0        NaN\n",
      "10  10     Simran Kaur           24    2023-02-12  32000.0  Marketing\n",
      "11  11             NaN           27    2021-09-14  36000.0         IT\n",
      "12  12     Vikas Yadav  twenty five    2022-12-01  40000.0         HR\n",
      "\n",
      "----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load Dataset\n",
    "df = pd.read_csv(\"dirty_data.csv\")\n",
    "\n",
    "print(\"Original Dataset:\\n\")\n",
    "print(df)\n",
    "print(\"\\n----------------------------------\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "560250ee-dfb8-4126-8481-77822ce226f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Cleaning Log\n",
    "log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c8d5523-84b3-4af6-8a49-28ed77e736d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'full_name', 'age', 'join_date', 'salary', 'department'], dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Standardize Column Names\n",
    "df.columns = df.columns.str.lower().str.replace(\" \", \"_\")\n",
    "log.append(\"Standardized column names\")\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1973654d-1be0-47b5-9923-84003a664059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            0\n",
       "full_name     1\n",
       "age           2\n",
       "join_date     0\n",
       "salary        1\n",
       "department    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Check Missing Values (Before)\n",
    "missing_before = df.isnull().sum()\n",
    "log.append(\"Checked missing values before cleaning\")\n",
    "missing_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1eab917-925e-4a32-bbfc-ff5205d60cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "74d4534d-7b80-42f2-ab11-21f878e222a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning Completed Successfully!\n",
      "    id       full_name   age  join_date   salary    department\n",
      "0    1    Rahul Sharma  25.0 2022-01-15  35000.0            IT\n",
      "1    2     Priya Verma  27.6 2022-01-15  42000.0            HR\n",
      "2    3      Amit Singh  28.0 2022-01-15  39000.0       Finance\n",
      "3    4      Neha Gupta  27.0 2022-03-10  38000.0            IT\n",
      "4    5     Rohit Kumar  30.0 2021-11-05  48000.0         Sales\n",
      "5    6    Anjali Mehta  29.0 2022-01-15  35000.0            IT\n",
      "7    7    Suresh Patel  27.6 2020-08-18  41000.0            HR\n",
      "8    8      Pooja Shah  26.0 2022-01-15  37000.0       Finance\n",
      "9    9  Karan Malhotra  31.0 2022-06-25  50000.0  Not Assigned\n",
      "10  10     Simran Kaur  24.0 2023-02-12  32000.0     Marketing\n",
      "11  11         Unknown  27.0 2021-09-14  36000.0            IT\n",
      "12  12     Vikas Yadav  27.6 2022-12-01  40000.0            HR\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"dirty_data.csv\")\n",
    "\n",
    "log = []\n",
    "\n",
    "# Convert column names\n",
    "df.columns = df.columns.str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# Fill missing full_name\n",
    "df['full_name'] = df['full_name'].fillna(\"Unknown\")\n",
    "log.append(\"Filled missing full_name with 'Unknown'\")\n",
    "\n",
    "# Convert age to numeric\n",
    "df['age'] = pd.to_numeric(df['age'], errors='coerce')\n",
    "\n",
    "# Fill missing age with mean\n",
    "df['age'] = df['age'].fillna(df['age'].mean())\n",
    "log.append(\"Converted age to numeric and filled missing age with mean\")\n",
    "\n",
    "# Convert salary to numeric\n",
    "df['salary'] = pd.to_numeric(df['salary'], errors='coerce')\n",
    "\n",
    "# Fill missing salary with median\n",
    "df['salary'] = df['salary'].fillna(df['salary'].median())\n",
    "log.append(\"Converted salary to numeric and filled missing salary with median\")\n",
    "\n",
    "# Fill missing department\n",
    "df['department'] = df['department'].fillna(\"Not Assigned\")\n",
    "log.append(\"Filled missing department with 'Not Assigned'\")\n",
    "\n",
    "# Convert join_date to datetime\n",
    "df['join_date'] = pd.to_datetime(df['join_date'], errors='coerce')\n",
    "\n",
    "# Fill missing join_date with mode\n",
    "df['join_date'] = df['join_date'].fillna(df['join_date'].mode()[0])\n",
    "log.append(\"Converted join_date to datetime and filled missing dates\")\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "log.append(\"Removed duplicate rows\")\n",
    "\n",
    "# Save cleaned data\n",
    "df.to_csv(\"cleaned_data.csv\", index=False)\n",
    "\n",
    "# Save log\n",
    "with open(\"cleaning_log.txt\", \"w\") as f:\n",
    "    for item in log:\n",
    "        f.write(item + \"\\n\")\n",
    "\n",
    "print(\"Cleaning Completed Successfully!\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "343243e9-c2b2-4e5e-9a9e-e3266d6e5707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Dataset:\n",
      "\n",
      "    id       full_name   age  join_date   salary    department\n",
      "0    1    Rahul Sharma  25.0 2022-01-15  35000.0            IT\n",
      "1    2     Priya Verma  27.6 2022-01-15  42000.0            HR\n",
      "2    3      Amit Singh  28.0 2022-01-15  39000.0       Finance\n",
      "3    4      Neha Gupta  27.0 2022-03-10  38000.0            IT\n",
      "4    5     Rohit Kumar  30.0 2021-11-05  48000.0         Sales\n",
      "5    6    Anjali Mehta  29.0 2022-01-15  35000.0            IT\n",
      "7    7    Suresh Patel  27.6 2020-08-18  41000.0            HR\n",
      "8    8      Pooja Shah  26.0 2022-01-15  37000.0       Finance\n",
      "9    9  Karan Malhotra  31.0 2022-06-25  50000.0  Not Assigned\n",
      "10  10     Simran Kaur  24.0 2023-02-12  32000.0     Marketing\n",
      "11  11         Unknown  27.0 2021-09-14  36000.0            IT\n",
      "12  12     Vikas Yadav  27.6 2022-12-01  40000.0            HR\n",
      "\n",
      "Missing Values After Cleaning:\n",
      "\n",
      "id            0\n",
      "full_name     0\n",
      "age           0\n",
      "join_date     0\n",
      "salary        0\n",
      "department    0\n",
      "dtype: int64\n",
      "\n",
      "----------------------------------\n",
      "Cleaning Completed Successfully!\n",
      "Output Files Created:\n",
      "1. cleaned_data.csv\n",
      "2. cleaning_log.txt\n"
     ]
    }
   ],
   "source": [
    "# Fill missing names\n",
    "df['full_name'] = df['full_name'].fillna(\"Unknown\")\n",
    "log.append(\"Filled missing full_name with 'Unknown'\")\n",
    "\n",
    "# Convert age to numeric\n",
    "df['age'] = pd.to_numeric(df['age'], errors='coerce')\n",
    "\n",
    "# Fill missing age with mean\n",
    "df['age'] = df['age'].fillna(df['age'].mean())\n",
    "log.append(\"Converted age to numeric and filled missing age with mean\")\n",
    "\n",
    "# Convert salary to numeric\n",
    "df['salary'] = pd.to_numeric(df['salary'], errors='coerce')\n",
    "\n",
    "# Fill missing salary with median\n",
    "df['salary'] = df['salary'].fillna(df['salary'].median())\n",
    "log.append(\"Converted salary to numeric and filled missing salary with median\")\n",
    "\n",
    "# Fill missing department\n",
    "df['department'] = df['department'].fillna(\"Not Assigned\")\n",
    "log.append(\"Filled missing department with 'Not Assigned'\")\n",
    "\n",
    "# Step 4: Fix Date Column\n",
    "df['join_date'] = pd.to_datetime(df['join_date'], errors='coerce')\n",
    "\n",
    "# Fill missing dates with most frequent date\n",
    "df['join_date'] = df['join_date'].fillna(df['join_date'].mode()[0])\n",
    "log.append(\"Converted join_date to datetime and filled missing dates\")\n",
    "\n",
    "# Step 5: Remove Duplicates\n",
    "duplicate_count = df.duplicated().sum()\n",
    "df = df.drop_duplicates()\n",
    "log.append(f\"Removed {duplicate_count} duplicate rows\")\n",
    "\n",
    "# Step 6: Final Missing Value Check\n",
    "missing_after = df.isnull().sum()\n",
    "log.append(\"Checked missing values after cleaning\")\n",
    "\n",
    "# Step 7: Save Cleaned Dataset\n",
    "df.to_csv(\"cleaned_data.csv\", index=False)\n",
    "log.append(\"Saved cleaned dataset as cleaned_data.csv\")\n",
    "\n",
    "# Step 8: Save Cleaning Log\n",
    "with open(\"cleaning_log.txt\", \"w\") as file:\n",
    "    for item in log:\n",
    "        file.write(item + \"\\n\")\n",
    "\n",
    "# Step 9: Display Results\n",
    "print(\"Cleaned Dataset:\\n\")\n",
    "print(df)\n",
    "\n",
    "print(\"\\nMissing Values After Cleaning:\\n\")\n",
    "print(missing_after)\n",
    "\n",
    "print(\"\\n----------------------------------\")\n",
    "print(\"Cleaning Completed Successfully!\")\n",
    "print(\"Output Files Created:\")\n",
    "print(\"1. cleaned_data.csv\")\n",
    "print(\"2. cleaning_log.txt\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f67edbb-6dc7-4325-860e-25ef97773427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
